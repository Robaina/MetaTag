
#To extract those hits with a score cluster over 0
cd /media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements
#Have a list with genes -> genes.txt

while read i ; do awk -F"\t" '$5>0.02' original_files/envision_${i}_placed_assignments.tsv > score_over_0_files/envision_${i}_placed_assignments_over0.tsv ; done < genes.txt 

# para manual
#awk -F"\t" '$5>0.02' ORIGINAL_TABLE > OUTPUT_TABLE

wc -l */*


#Once we have the right hits, double check duplicates that have been excluded previously. For nxr there is no hit. Choose only narG file
# amoA and nosZ duplicates are not different ORFs but the same ORF caught by different domains. 
# hzsA and nirS has no duplicates

# For the rest:
cd /media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/replicate_hits

#Have a list with genes with duplicates:

# cat duplicates_list.txt
#amoA
#amt
#nas
#nifH
#nirK
# no duplicates in other genes


while read i ; do cut -f 2 ../../../${i}/data/*_duplicates.txt | sed 's/,/\t/' | sed 's/ //g' > ${i}_duplicates ; done < duplicates_list.txt

#Ir a R y correr lo siguiente
###### REVISA LAS PATHS DE LOS ASSIGMENTS #########
# amoA
duplicated_hits <- read.table("./amoA_duplicates")
assigments <- read.csv("/media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/original_files/envision_amoA_placed_assignments.tsv", header=TRUE, sep="\t")
combi_tab <- merge(duplicated_hits, assigments, by.x="V1", by.y="query_name")
combi_tab_clean <- combi_tab[,c(3,2,4,5,6,7,8)]
write.table(combi_tab_clean, file="./amoA_duplicate_table", quote=FALSE, col.names=FALSE, row.names=FALSE, sep="\t")

#amt 
duplicated_hits <- read.table("./amt_duplicates")
assigments <- read.csv("/media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/original_files/envision_amt_placed_assignments.tsv", header=TRUE, sep="\t")
combi_tab <- merge(duplicated_hits, assigments, by.x="V1", by.y="query_name")
combi_tab_clean <- combi_tab[,c(3,2,4,5,6,7,8)]
write.table(combi_tab_clean, file="./amt_duplicate_table", quote=FALSE, col.names=FALSE, row.names=FALSE, sep="\t")

# nas
duplicated_hits <- read.table("./nas_duplicates")
assigments <- read.csv("/media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/original_files/envision_nas_placed_assignments.tsv", header=TRUE, sep="\t")
combi_tab <- merge(duplicated_hits, assigments, by.x="V1", by.y="query_name")
combi_tab_clean <- combi_tab[,c(3,2,4,5,6,7,8)]
write.table(combi_tab_clean, file="./nas_duplicate_table", quote=FALSE, col.names=FALSE, row.names=FALSE, sep="\t")

#nifH
duplicated_hits <- read.table("./nifH_duplicates")
assigments <- read.csv("/media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/original_files/envision_nifH_placed_assignments.tsv", header=TRUE, sep="\t")
combi_tab <- merge(duplicated_hits, assigments, by.x="V1", by.y="query_name")
combi_tab_clean <- combi_tab[,c(3,2,4,5,6,7,8)]
write.table(combi_tab_clean, file="./nifH_duplicate_table", quote=FALSE, col.names=FALSE, row.names=FALSE, sep="\t")

#nirK
duplicated_hits <- read.table("./nirK_duplicates")
assigments <- read.csv("/media/disk5/nfernandez/TRAITS/genes/envision/n_cycle_placements/original_files/envision_nirK_placed_assignments.tsv", header=TRUE, sep="\t")
combi_tab <- merge(duplicated_hits, assigments, by.x="V1", by.y="query_name")
combi_tab_clean <- combi_tab[,c(3,2,4,5,6,7,8)]
write.table(combi_tab_clean, file="./nirK_duplicate_table", quote=FALSE, col.names=FALSE, row.names=FALSE, sep="\t")

# Other genes do not need any further processing.

# remove scores > 0 for duplicates
while read i ; do awk -F"\t" '$5>0.02' ${i}_duplicate_table | sed 's/,/\t/' | sed 's/ //g' > ${i}_duplicate_table_scoreover0 ; done < duplicates_list.txt

#Add funcolumn
while read i ; do sed "/megahit/s/$/\t$i/" ${i}_duplicate_table_scoreover0 > ${i}_duplicate_table_scoreover0_funcolumn ; done < duplicates_list.txt


#Add a final column with the gene function
while read i ; do sed "/megahit/s/$/\t$i/" ../score_over_0_files/envision_${i}_placed_assignments_over0.tsv | sed '/query_id/s/taxopath$/taxopath\tgene_fun/' > ../score_over_0_files/envision_${i}_placed_assignments_over0_funcolumn.tsv ; done < ../genes.txt

cd ..
#Put together all tables
cat score_over_0_files/envision_amoA_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_amt_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_hzsA_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_narG_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nas_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nifH_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nirK_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nirS_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nosZ_placed_assignments_over0_funcolumn.tsv \
    score_over_0_files/envision_nrtA_placed_assignments_over0_funcolumn.tsv\
    score_over_0_files/envision_nxrA_placed_assignments_over0_funcolumn.tsv\
    replicate_hits/amoA_duplicate_table_scoreover0_funcolumn \
    replicate_hits/amt_duplicate_table_scoreover0_funcolumn \
    replicate_hits/nifH_duplicate_table_scoreover0_funcolumn \
    replicate_hits/nirK_duplicate_table_scoreover0_funcolumn \
    replicate_hits/nas_duplicate_table_scoreover0_funcolumn > all_arctic_genes_assignments_scoreover0_funcolumn.tsv 

#remove extra headers (keep 1st line and the rest with megahit)
#query_id        query_name      LWR     cluster_id      cluster_score   cluster_taxopath        taxopath   gene_id
sed -n -i '1p; /megahit/p' all_arctic_genes_assignments_scoreover0_funcolumn.tsv

#Get the list of ORFs
grep "megahit" all_arctic_genes_assignments_scoreover0_funcolumn.tsv | cut -f 2 > orf_list_arctic_assignments_scoreover0

#Extract from the SQM project the abundances (in R)
R
library('SQMtools')

artico = loadSQM('/data/mcm/rlaso/Traits/Arctic_analysis/artico022_DNA/')


tax_image_phylum =  plotTaxonomy(artico, rank='phylum', count='percent', 
    metadata_groups = list ('DNA'=c('9_Mar','13_Mar','17_Mar','23_Apr','1_May','5_May','10_May','19_May','1_Jun','11_Jun','15_Jun','23_Jun','30_Jul') , 'RNA'=c('9_Mar_RNA','11_Mar_RNA','17_Mar_RNA','23_Apr_RNA','1_May_RNA','15_May_RNA','19_May_RNA','1_Jun_RNA','11_Jun_RNA','15_Jun_RNA','23_Jun_RNA')), samples=c('9_Mar','13_Mar','17_Mar','23_Apr','1_May','5_May','10_May','19_May','1_Jun','11_Jun','15_Jun','23_Jun','30_Jul','11_Mar_RNA','17_Mar_RNA','15_May_RNA','1_Jun_RNA','11_Jun_RNA','15_Jun_RNA','23_Jun_RNA'), color= colour_set)

tax_image_class =  plotTaxonomy(artico, rank='class', count='percent', metadata_groups = list ('DNA'=c('9_Mar','13_Mar','17_Mar','23_Apr','1_May','5_May','1
0_May','19_May','1_Jun','11_Jun','15_Jun','23_Jun','30_Jul') , 'RNA'=c('11_Mar_RNA','17_Mar_RNA','15_May_RNA','1_Jun_RNA','11_Jun_RNA','15_Jun_RNA','23_Jun_RN
A')), samples=c('9_Mar','13_Mar','17_Mar','23_Apr','1_May','5_May','10_May','19_May','1_Jun','11_Jun','15_Jun','23_Jun','30_Jul','11_Mar_RNA','17_Mar_RNA','15
_May_RNA','1_Jun_RNA','11_Jun_RNA','15_Jun_RNA','23_Jun_RNA'), color= c("#969696","#1F74CD","#5D478B","#d9d9d9","#FCD84A","#CD672F","#cab2d6","#6a3d9a","#E018
53","#CD672F","#b15928","#E01853","#F6BFCA","#8B461D","#E01853"))
ggsave(file='./R_analysis/results/tax_class.pdf', plot=tax_image_class)
ggsave(file='./R_analysis/results/tax_class.png', plot=tax_image_class)

colour_set <- c("#CD672F", #Btes
+  "#F6BFCA", #Planct
+  "#8B461D", #Verru
+  "#FCD84A", #Actin
+  "#E01853", #Archa
+  "#1F74CD", #Alpha
+  "#5D478B"  #Gamma
+  )
> names(colour_set) <- c("Bacteroidetes",
+  "Planctomycetes",
+   "Verrucomicrobia",
+    "Actinobacteria",
+    "Archaea",
+   "Alphaproteobacteria",
+   "Gammaproteobacteria")


#Work on the subset
#Import orfs and make a vector for subsetORFs
orf_list <- read.table("/data/mcm/rlaso/Traits/Arctic_analysis/Nitrogen_cycle_placement/summary_placement/orf_list_arctic_assignments_scoreover0", header=FALSE)
#make as a vector
orf_list <- as.character(orf_list[,1])
#Make the subset and export it
artic_subset <- subsetORFs(artico, orf_list)
write.table(artico_subset$orfs$table, file="/data/mcm/rlaso/Traits/Arctic_analysis/Nitrogen_cycle_placement/summary_placement/13.artico022_DNA.orftable_subset", quote=FALSE, col.names=TRUE, row.names=TRUE, sep="\t")

#Export tables to my own computer and work in R


### OLD STEPS ####
python3 /data/mcm/rlaso/Programs/TRAITS/code/squeezemodify.py --squeeze_table 13.artico022_DNA.orftable --taxplacement_table /data/mcm/rlaso/Traits/Arctic_analysis/Nitrogen_cycle_placement/summary_placement/all_arctic_genes_assignments_scoreover0.tsv -o ./13.artico022_DNA.orftable_GTDB_tax
python3 /data/mcm/rlaso/Programs/TRAITS/code/squeezemodify.py --squeeze_table 08.artico022_DNA.fun3.tax.noidfilter.wranks --taxplacement_table /data/mcm/rlaso/Traits/Arctic_analysis/Nitrogen_cycle_placement/summary_placement/all_arctic_genes_assignments_scoreover0.tsv -o ./08.artico022_DNA.fun3.tax.noidfilter.wranks_GTDB
#Substitute the corresponding files
#Then try to produce the R project
arctic_GTDB = loadSQM('/data/mcm/rlaso/Traits/Arctic_analysis/artico022_DNA_phylogeny_GTDB/')
subsetORFs


