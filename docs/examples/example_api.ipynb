{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/Robaina/Pynteny/blob/main/docs/examples/example_api_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/21340147/227912321-f76e622a-684d-48a9-8ead-9a2ce7caebe9.png\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "[Semid√°n Robaina](https://github.com/Robaina), February 2023.\n",
    "\n",
    "In this Notebook, we will use MetaTag through its Python API to reconstruct a phylogenetic tree. To this end, we will use peptide sequences from the [MARref database](https://mmp2.sfb.uit.no/marref/) and a profile HMM to identify sequences beloging to the X gene.\n",
    "\n",
    "- Note that we could have conducted the same search through Pynteny's command-line interface.\n",
    "\n",
    "- Find more info in the [documentation pages](https://robaina.github.io/MetaTag/)!\n",
    "\n",
    "Let's start by importing some required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import DataFrame\n",
    "from metatag.cli import MetaTag\n",
    "from metatag.visualization import make_tree_html\n",
    "from metatag.pipelines import ReferenceTreeBuilder, QueryLabeller, QueryProcessor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a directory to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dir = Path(\"../../tests\")\n",
    "outdir = Path(\"example_api/results\")\n",
    "# outdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Marref database:\n",
    "\n",
    "Download the [MarRef](https://mmp2.sfb.uit.no/marref/) database and extract contents. We will use the `protein.faa` file, containing translated peptide sequences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infering a gene-specific phylogenetic tree\n",
    "\n",
    "We will infer a phylogenetic tree for the gene _nifH_. To this end, we will use the TIGRFAM profile HMM for this gene: [TIGR01287](), as well as [TIGR02016](), corresponding to gene _BCHX_ which serves as an outgroup. The class `ReferenceTreeBuilder` will take care of all necessary steps to infer the tree. Namely, (i) preprocess the input marref database, (ii) build a reference database containing a maximum of 20 nifH and 5 BCHX representative sequences, using both [CD-Hit]() and [RepSet](), (iii) align the reference sequences with [MUSCLE](), (iv) infer a phylogenetic tree from the alignment with [FastTree]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:06:20,221 | INFO: Removing duplicates...\n",
      "2023-03-30 14:06:42,084 | INFO: Asserting correct sequence format...\n",
      "2023-03-30 14:08:14,125 | INFO: Done!\n",
      "2023-03-30 14:08:14,127 | INFO: Making peptide-specific reference database...\n",
      "2023-03-30 14:08:14,128 | INFO: Processing hmm TIGR01287.1 with additional arguments: --cut_ga\n",
      "2023-03-30 14:08:14,130 | INFO: Running Hmmer...\n",
      "2023-03-30 14:08:20,107 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 14:08:20,118 | INFO: Filtering Fasta...\n",
      "2023-03-30 14:08:21,025 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 14:08:21,226 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-30 14:08:21,719 | INFO: Relabelling records in reference database...\n",
      "2023-03-30 14:08:21,721 | INFO: Processing hmm TIGR02016.1 with additional arguments: --cut_ga\n",
      "2023-03-30 14:08:21,723 | INFO: Running Hmmer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:08:21,526 INFO:Reading PI database...\n",
      "2023-03-30 14:08:21,526 INFO:Building dataframe\n",
      "2023-03-30 14:08:21,530 INFO:Dataframe built\n",
      "2023-03-30 14:08:21,617 INFO:Finished building database...\n",
      "2023-03-30 14:08:21,617 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-30 14:08:21,617 INFO:Repset size: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:08:27,737 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 14:08:27,741 | INFO: Filtering Fasta...\n",
      "2023-03-30 14:08:28,912 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 14:08:29,096 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-30 14:08:29,526 | INFO: Relabelling records in reference database...\n",
      "2023-03-30 14:08:29,530 | INFO: Done!\n",
      "2023-03-30 14:08:29,531 | INFO: Aligning reference database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:08:29,417 INFO:Reading PI database...\n",
      "2023-03-30 14:08:29,417 INFO:Building dataframe\n",
      "2023-03-30 14:08:29,420 INFO:Dataframe built\n",
      "2023-03-30 14:08:29,431 INFO:Finished building database...\n",
      "2023-03-30 14:08:29,431 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-30 14:08:29,431 INFO:Repset size: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:08:29,678 | INFO: Inferring reference tree...\n",
      "2023-03-30 14:08:31,576 | INFO: Done!\n",
      "2023-03-30 14:08:31,577 | INFO: Relabelling tree...\n",
      "2023-03-30 14:08:31,842 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "tree_builder = ReferenceTreeBuilder(\n",
    "    input_database=Path(\"/home/robaina/Databases/MAR_database/protein.faa\"),\n",
    "    hmms=[\n",
    "        (tests_dir / \"test_data\" / \"TIGR01287.1.HMM\").as_posix(),\n",
    "        (tests_dir / \"test_data\" / \"TIGR02016.1.HMM\").as_posix(),\n",
    "    ],\n",
    "    maximum_hmm_reference_sizes=[50, 5],\n",
    "    relabel_prefixes=[\"ref_\", \"out_\"],\n",
    "    relabel=True,\n",
    "    remove_duplicates=True,\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    output_directory=outdir,\n",
    "    msa_method=\"muscle\",\n",
    "    tree_method=\"fasttree\",\n",
    "    tree_model=\"JTT\",\n",
    ")\n",
    "tree_builder.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the generated tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robaina/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/empress/tree.py:79: TreeFormatWarning: Internal node names in the tree are not unique.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_tree_html(tree_builder.reference_tree, output_dir=outdir / \"tree_plot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"file:///home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot/empress.html\" target=\"_blank\"><img src=\"example_api/example_tree.png\" style=\"width:50%;\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess metagenomic data\n",
    "\n",
    "We need to first preprocess the metagenomic data to remove low quality reads as well as to prefilter sequences using the same profile HMM used to infer the phylogenetic tree. This will reduce the computational cost of the placement step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:10:21,488 | INFO: Removing duplicates...\n",
      "2023-03-30 14:10:24,016 | INFO: Asserting correct sequence format...\n",
      "2023-03-30 14:10:39,407 | INFO: Relabelling records...\n",
      "2023-03-30 14:10:40,757 | INFO: Done!\n",
      "2023-03-30 14:10:40,759 | INFO: Making peptide-specific reference database...\n",
      "2023-03-30 14:10:40,761 | INFO: Processing hmm TIGR01287.1 with additional arguments: --cut_ga\n",
      "2023-03-30 14:10:40,762 | INFO: Running Hmmer...\n",
      "2023-03-30 14:10:41,631 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 14:10:41,637 | INFO: Filtering Fasta...\n",
      "2023-03-30 14:10:41,786 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 14:10:41,797 | INFO: No reduction algorithm has been selected.\n",
      "2023-03-30 14:10:41,818 | WARNING: Could not delete temporary files: [Errno 2] No such file or directory: '/tmp/tmp2mvx5e3s'\n",
      "2023-03-30 14:10:41,819 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "processor = QueryProcessor(\n",
    "    input_query=Path(\"/home/robaina/Databases/Uniprot/uniprot_sprot.fasta\"),\n",
    "    hmm=tests_dir / \"test_data\" / \"TIGR01287.1.HMM\",\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    minimum_sequence_length=30,\n",
    "    output_directory=outdir,\n",
    "    relabel=True,\n",
    ")\n",
    "processor.run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place and label metagenomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 14:14:39,092 | INFO: Placing reads on tree...\n",
      "2023-03-30 14:14:40,496 | INFO: Writing tree with placements...\n",
      "2023-03-30 14:14:40,504 | INFO: Done!\n",
      "2023-03-30 14:14:40,506 | INFO: Filtering placements by maximum distance: \"pendant_diameter_ratio\" of 1.0\n",
      "2023-03-30 14:14:40,512 | INFO: Filtering placements for tree diameter: 3.1206669510000005\n",
      "2023-03-30 14:14:40,515 | INFO: Filtering placements by minimum LWR of: 0.8\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ref_20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m      1\u001b[0m labeller \u001b[39m=\u001b[39m QueryLabeller(\n\u001b[1;32m      2\u001b[0m     input_query\u001b[39m=\u001b[39mprocessor\u001b[39m.\u001b[39mfiltered_query,\n\u001b[1;32m      3\u001b[0m     skip_preprocessing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     minimum_placement_lwr\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m,\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m labeller\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/metatag/pipelines.py:475\u001b[0m, in \u001b[0;36mQueryLabeller.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m placesequences\u001b[39m.\u001b[39mrun(place_args)\n\u001b[1;32m    459\u001b[0m assign_args \u001b[39m=\u001b[39m CommandArgs(\n\u001b[1;32m    460\u001b[0m     jplace\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jplace,\n\u001b[1;32m    461\u001b[0m     labels\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreference_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m     logfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logfile,\n\u001b[1;32m    474\u001b[0m )\n\u001b[0;32m--> 475\u001b[0m labelplacements\u001b[39m.\u001b[39;49mrun(assign_args)\n\u001b[1;32m    477\u001b[0m count_args \u001b[39m=\u001b[39m CommandArgs(\n\u001b[1;32m    478\u001b[0m     taxtable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_out_taxtable,\n\u001b[1;32m    479\u001b[0m     taxlevels\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mgenus\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfamily\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morder\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclass\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mphylum\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m     logfile\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_logfile,\n\u001b[1;32m    486\u001b[0m )\n\u001b[1;32m    487\u001b[0m countplacements\u001b[39m.\u001b[39mrun(count_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/metatag/scripts/labelplacements.py:262\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    257\u001b[0m     jplaceparser\u001b[39m.\u001b[39mfilter_placements_by_minimum_lwr(\n\u001b[1;32m    258\u001b[0m         minimum_lwr\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mminimum_lwr, output_file\u001b[39m=\u001b[39mfiltered_jplace\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m     args\u001b[39m.\u001b[39mjplace \u001b[39m=\u001b[39m filtered_jplace\n\u001b[0;32m--> 262\u001b[0m assign_labels_to_placements(\n\u001b[1;32m    263\u001b[0m     jplace\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mjplace,\n\u001b[1;32m    264\u001b[0m     ref_labels\u001b[39m=\u001b[39;49mref_labels,\n\u001b[1;32m    265\u001b[0m     query_labels\u001b[39m=\u001b[39;49mquery_labels,\n\u001b[1;32m    266\u001b[0m     output_dir\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49moutdir,\n\u001b[1;32m    267\u001b[0m     output_prefix\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mprefix,\n\u001b[1;32m    268\u001b[0m     only_best_hit\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    269\u001b[0m     ref_clusters_file\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mref_clusters,\n\u001b[1;32m    270\u001b[0m     ref_cluster_scores_file\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mref_cluster_scores,\n\u001b[1;32m    271\u001b[0m     gappa_additional_args\u001b[39m=\u001b[39;49margs_str,\n\u001b[1;32m    272\u001b[0m     only_unique_cluster\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     taxo_file\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mtaxofile,\n\u001b[1;32m    274\u001b[0m )\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mduplicated_query_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     add_duplicates_to_assignment_table(taxtable, args\u001b[39m.\u001b[39mduplicated_query_ids)\n",
      "File \u001b[0;32m~/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/metatag/placement.py:627\u001b[0m, in \u001b[0;36massign_labels_to_placements\u001b[0;34m(jplace, ref_labels, query_labels, output_dir, output_prefix, only_best_hit, ref_clusters_file, ref_cluster_scores_file, gappa_additional_args, only_unique_cluster, taxo_file)\u001b[0m\n\u001b[1;32m    624\u001b[0m taxonomy\u001b[39m.\u001b[39mbuild_gappa_taxonomy_table(ref_labels, output_file\u001b[39m=\u001b[39mtemptax)\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m has_cluster_id:\n\u001b[0;32m--> 627\u001b[0m     add_clusters_to_tax_table(\n\u001b[1;32m    628\u001b[0m         in_taxtable\u001b[39m=\u001b[39;49mtemptax, clusters\u001b[39m=\u001b[39;49mref_clusters, out_taxtable\u001b[39m=\u001b[39;49mtemptax\n\u001b[1;32m    629\u001b[0m     )\n\u001b[1;32m    630\u001b[0m     clusters_taxopath \u001b[39m=\u001b[39m taxonomy\u001b[39m.\u001b[39massign_lowest_common_taxonomy_to_clusters(\n\u001b[1;32m    631\u001b[0m         clusters\u001b[39m=\u001b[39mref_clusters_as_keys, label_dict\u001b[39m=\u001b[39mref_labels\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/metatag/placement.py:434\u001b[0m, in \u001b[0;36madd_clusters_to_tax_table\u001b[0;34m(in_taxtable, clusters, out_taxtable)\u001b[0m\n\u001b[1;32m    432\u001b[0m taxtable \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(in_taxtable, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m)\n\u001b[1;32m    433\u001b[0m \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m taxtable\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m--> 434\u001b[0m     row[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m clusters[row[\u001b[39m0\u001b[39;49m]] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m row[\u001b[39m1\u001b[39m]\n\u001b[1;32m    435\u001b[0m taxtable\u001b[39m.\u001b[39mto_csv(out_taxtable, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ref_20'"
     ]
    }
   ],
   "source": [
    "labeller = QueryLabeller(\n",
    "    input_query=processor.filtered_query,\n",
    "    skip_preprocessing=True,\n",
    "    reference_alignment=tree_builder.reference_alignment,\n",
    "    reference_tree=tree_builder.reference_tree,\n",
    "    reference_labels=[\n",
    "        tree_builder.reference_labels\n",
    "    ],\n",
    "    tree_model=\"JTT\",\n",
    "    tree_clusters=tests_dir / \"test_data\" / \"clusters.tsv\",\n",
    "    tree_cluster_scores=tests_dir / \"test_data\" / \"cluster_scores.tsv\",\n",
    "    tree_cluster_score_threshold=0.6,\n",
    "    alignment_method=\"papara\",\n",
    "    output_directory=outdir,\n",
    "    maximum_placement_distance=1.0,\n",
    "    distance_measure=\"pendant_diameter_ratio\",\n",
    "    minimum_placement_lwr=0.8,\n",
    ")\n",
    "labeller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation\n",
    "\n",
    "We can get the citation string by calling the `cite` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this software, please cite it as below: \n",
      "Semid√°n Robaina Est√©vez (2022). MetaTag: Metagenome functional and taxonomical annotation through phylogenetic tree placement.(Version 0.1.0). Zenodo.\n"
     ]
    }
   ],
   "source": [
    "MetaTag.cite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pynteny')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a61de4707cf6170489d2ddea2edd86c71e80569b354848770f4168884b6914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
