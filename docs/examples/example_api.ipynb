{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/Robaina/Pynteny/blob/main/docs/examples/example_api_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](https://user-images.githubusercontent.com/21340147/227912321-f76e622a-684d-48a9-8ead-9a2ce7caebe9.png)\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "[Semidán Robaina](https://github.com/Robaina), February 2023.\n",
    "\n",
    "In this Notebook, we will use MetaTag through its Python API to reconstruct a phylogenetic tree. To this end, we will use peptide sequences from the [MARref database](https://mmp2.sfb.uit.no/marref/) and a profile HMM to identify sequences beloging to the X gene.\n",
    "\n",
    "- Note that we could have conducted the same search through Pynteny's command-line interface.\n",
    "\n",
    "- Find more info in the [documentation pages](https://robaina.github.io/MetaTag/)!\n",
    "\n",
    "Let's start by importing some required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pandas import DataFrame\n",
    "from metatag.cli import MetaTag\n",
    "from metatag.pipelines import ReferenceTreeBuilder, QueryLabeller, QueryProcessor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a directory to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"example_api/data\").mkdir(exist_ok=False, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Uniprot reference database:\n",
    "\n",
    "[Uniprot](https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infer gene-specific phylogenetic tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:50:21,320 | INFO: Removing duplicates...\n",
      "2023-03-27 23:50:24,108 | INFO: Asserting correct sequence format...\n",
      "2023-03-27 23:50:38,723 | INFO: Done!\n",
      "2023-03-27 23:50:38,725 | INFO: Making peptide-specific reference database...\n",
      "2023-03-27 23:50:38,726 | INFO: Processing hmm TIGR01287.1 with additional arguments: --cut_nc\n",
      "2023-03-27 23:50:38,727 | INFO: Running Hmmer...\n",
      "2023-03-27 23:50:39,703 | INFO: Parsing Hmmer output file...\n",
      "2023-03-27 23:50:39,753 | INFO: Filtering Fasta...\n",
      "2023-03-27 23:50:39,937 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-27 23:50:40,144 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-27 23:50:40,564 | INFO: Relabelling records in reference database...\n",
      "2023-03-27 23:50:40,566 | INFO: Processing hmm TIGR02016.1 with additional arguments: --cut_ga\n",
      "2023-03-27 23:50:40,567 | INFO: Running Hmmer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:50:40,395 INFO:Reading PI database...\n",
      "2023-03-27 23:50:40,396 INFO:Building dataframe\n",
      "2023-03-27 23:50:40,400 INFO:Dataframe built\n",
      "2023-03-27 23:50:40,476 INFO:Finished building database...\n",
      "2023-03-27 23:50:40,476 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-27 23:50:40,476 INFO:Repset size: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:50:41,565 | INFO: Parsing Hmmer output file...\n",
      "2023-03-27 23:50:41,567 | INFO: Filtering Fasta...\n",
      "2023-03-27 23:50:41,785 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-27 23:50:41,938 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-27 23:50:42,288 | INFO: Relabelling records in reference database...\n",
      "2023-03-27 23:50:42,291 | INFO: Done!\n",
      "2023-03-27 23:50:42,293 | INFO: Aligning reference database...\n",
      "2023-03-27 23:50:42,339 | INFO: Inferring reference tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:50:42,197 INFO:Reading PI database...\n",
      "2023-03-27 23:50:42,197 INFO:Building dataframe\n",
      "2023-03-27 23:50:42,200 INFO:Dataframe built\n",
      "2023-03-27 23:50:42,201 INFO:Finished building database...\n",
      "2023-03-27 23:50:42,201 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-27 23:50:42,201 INFO:Repset size: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 23:50:42,957 | INFO: Done!\n",
      "2023-03-27 23:50:42,959 | INFO: Relabelling tree...\n",
      "2023-03-27 23:50:43,212 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "tests_dir = Path(\"/home/robaina/Documents/MetaTag/tests\")\n",
    "outdir = Path(\"example_api/results\")\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "tree_builder = ReferenceTreeBuilder(\n",
    "    input_database=Path(\"/home/robaina/Downloads/uniprot_sprot.fasta\"),\n",
    "    hmms=[\n",
    "        (tests_dir / \"test_data\" / \"TIGR01287.1.HMM\").as_posix(),\n",
    "        (tests_dir / \"test_data\" / \"TIGR02016.1.HMM\").as_posix(),\n",
    "    ],\n",
    "    maximum_hmm_reference_sizes=[20, 5],\n",
    "    relabel_prefixes=[\"ref_\", \"out_\"],\n",
    "    relabel=True,\n",
    "    remove_duplicates=True,\n",
    "    hmmsearch_args=\"None, --cut_ga\",\n",
    "    output_directory=outdir,\n",
    "    msa_method=\"muscle\",\n",
    "    tree_method=\"fasttree\",\n",
    "    tree_model=\"iqtest\",\n",
    ")\n",
    "tree_builder.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the generated tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metatag.visualization import plot_tree_in_browser, make_tree_html\n",
    "\n",
    "\n",
    "# tree_path = \"/home/robaina/Documents/MetaTag/docs/examples/example_api/results/ref_database.newick\"\n",
    "outdir = Path(\"/home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot\")\n",
    "\n",
    "# def plot_tree(button):\n",
    "#     plot_tree_in_browser(\n",
    "#         tree_builder.reference_tree,\n",
    "#         output_dir=outdir,\n",
    "#     )\n",
    "\n",
    "# make_tree_html(tree_builder.reference_tree, output_dir=outdir.as_posix())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"file:///home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot/empress.html\" target=\"_blank\"><img src=\"example_api/empress-tree.png\" style=\"width:50%;\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess metagenomic data\n",
    "\n",
    "We need to first preprocess the metagenomic data to remove low quality reads as well as to prefilter sequences using the same profile HMM used to infer the phylogenetic tree. This will reduce the computational cost of the placement step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = QueryProcessor(\n",
    "    input_query=Path(\"/home/robaina/Downloads/uniprot_sprot.fasta\"),\n",
    "    hmm=tests_dir / \"test_data\" / \"TIGR01287.1.HMM\",\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    minimum_sequence_length=30,\n",
    "    output_directory=outdir,\n",
    ")\n",
    "processor.run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place and label metagenomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeller = QueryLabeller(\n",
    "    input_query=processor.filtered_query,\n",
    "    reference_alignment=tree_builder._out_reference_alignment,\n",
    "    reference_tree=tree_builder._out_reference_tree,\n",
    "    reference_labels=[\n",
    "        (Path(tempdir) / \"ref_database_id_dict.pickle\").as_posix()\n",
    "    ],\n",
    "    tree_model=\"JTT\",\n",
    "    tree_clusters=tests_dir / \"test_data\" / \"clusters.tsv\",\n",
    "    tree_cluster_scores=tests_dir / \"test_data\" / \"cluster_scores.tsv\",\n",
    "    tree_cluster_score_threshold=0.6,\n",
    "    alignment_method=\"papara\",\n",
    "    output_directory=tempdir,\n",
    "    maximum_placement_distance=1.0,\n",
    "    distance_measure=\"pendant_diameter_ratio\",\n",
    "    minimum_placement_lwr=0.8,\n",
    ")\n",
    "labeller.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation\n",
    "\n",
    "We can get the citation string by calling the `cite` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this software, please cite it as below: \n",
      "Semidán Robaina Estévez (2022). MetaTag: Metagenome functional and taxonomical annotation through phylogenetic tree placement.(Version 0.1.0). Zenodo.\n"
     ]
    }
   ],
   "source": [
    "MetaTag.cite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pynteny')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a61de4707cf6170489d2ddea2edd86c71e80569b354848770f4168884b6914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
