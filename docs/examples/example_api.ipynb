{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/Robaina/Pynteny/blob/main/docs/examples/example_api_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/21340147/227912321-f76e622a-684d-48a9-8ead-9a2ce7caebe9.png\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "[Semidán Robaina](https://github.com/Robaina), February 2023.\n",
    "\n",
    "In this Notebook, we will use MetaTag through its Python API to taxonomically and functionally annotate unlabelled sequences. To this end, we will use peptide sequences from the [Ocean Microbiome](https://microbiomics.io/ocean/supp_info/) database and a profile HMM to identify sequences beloging to the gene [_nosZ_](https://www.uniprot.org/uniprotkb/Q51705/entry).\n",
    "\n",
    "- Note that we could have conducted the same pipeline through MetaTag's command-line interface.\n",
    "\n",
    "- Find more info in the [documentation pages](https://robaina.github.io/MetaTag/)!\n",
    "\n",
    "Let's start by importing some required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from metatag.cli import MetaTag\n",
    "from metatag.utils import DictMerger\n",
    "from metatag.visualization import make_tree_html\n",
    "from metatag.pipelines import ReferenceTreeBuilder, QueryLabeller, QueryProcessor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a directory to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = Path(\"example_api\")\n",
    "outdir = workdir / \"results\"\n",
    "outdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download OceanMicrobiome database and assign GTDB taxonomy:\n",
    "\n",
    "Download the [OceanMicrobiome](https://sunagawalab.ethz.ch/share/microbiomics/ocean/suppl_data/) database. Specifically, we will use all `representative genomes´.\n",
    "\n",
    "We also need to download two profile HMMs, click on them two download: [TIGR04244](https://ftp.ncbi.nlm.nih.gov/hmm/current/hmm_PGAP.HMM/TIGR04244.1.HMM) and [TIGR04246](https://ftp.ncbi.nlm.nih.gov/hmm/current/hmm_PGAP.HMM/TIGR04246.1.HMM)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve GTDB taxonomy\n",
    "\n",
    "To this end, we will extract that info from the MAR ref database itself, which provides a metadata file that contains GTDB taxonomical information for each genome in it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infering a gene-specific phylogenetic tree\n",
    "\n",
    "We will infer a phylogenetic tree for the gene [_nosZ_](https://www.uniprot.org/uniprotkb/Q51705/entry), encoding a nitrous oxide reductase that participates in the nitrogen cycle. To this end, we will use two TIGRFAM profile HMMs: [TIGR04244.1](https://www.ncbi.nlm.nih.gov/genome/annotation_prok/evidence/TIGR04244/), which encondes a TAT-dependent nitrous-oxide reductase, and [TIGR04246.1](https://www.ncbi.nlm.nih.gov/genome/annotation_prok/evidence/TIGR04246/), which encondes a SEC-dependent nitrous-oxide reductase.\n",
    "\n",
    "The class `ReferenceTreeBuilder` will take care of all necessary steps to infer the tree. Namely, (i) preprocess the input marref database, (ii) build a reference database containing a maximum of 20 nifH and 5 BCHX representative sequences, using both [CD-Hit](https://github.com/weizhongli/cdhit) and [RepSet](https://onlinelibrary.wiley.com/doi/10.1002/prot.25461), (iii) align the reference sequences with [MUSCLE](https://github.com/EddyRivasLab/hmmer), (iv) infer a phylogenetic tree from the alignment with [FastTree](https://github.com/PavelTorgashov/FastTree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 22:59:58,834 | INFO: Removing duplicates...\n",
      "2023-04-08 23:02:01,402 | INFO: Asserting correct sequence format...\n",
      "2023-04-08 23:08:59,960 | INFO: Done!\n",
      "2023-04-08 23:08:59,961 | INFO: Making peptide-specific reference database...\n",
      "2023-04-08 23:08:59,962 | INFO: Processing hmm TIGR04244.1 with additional arguments: --cut_ga\n",
      "2023-04-08 23:08:59,963 | INFO: Running Hmmer...\n",
      "2023-04-08 23:09:32,214 | INFO: Parsing Hmmer output file...\n",
      "2023-04-08 23:09:32,268 | INFO: Filtering Fasta...\n",
      "2023-04-08 23:09:41,495 | INFO: Filtering sequences by established length bounds...\n",
      "2023-04-08 23:09:41,869 | INFO: Finding representative sequences for reference database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:09:42,155 INFO:Reading PI database...\n",
      "2023-04-08 23:09:42,155 INFO:Building dataframe\n",
      "2023-04-08 23:09:42,177 INFO:Dataframe built\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:09:42,684 | INFO: Relabelling records in reference database...\n",
      "2023-04-08 23:09:42,686 | INFO: Processing hmm TIGR04246.1 with additional arguments: --cut_ga\n",
      "2023-04-08 23:09:42,686 | INFO: Running Hmmer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:09:42,550 INFO:Finished building database...\n",
      "2023-04-08 23:09:42,550 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-04-08 23:09:42,550 INFO:Repset size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:10:15,324 | INFO: Parsing Hmmer output file...\n",
      "2023-04-08 23:10:15,339 | INFO: Filtering Fasta...\n",
      "2023-04-08 23:10:25,570 | INFO: Filtering sequences by established length bounds...\n",
      "2023-04-08 23:10:25,937 | INFO: Finding representative sequences for reference database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:10:26,224 INFO:Reading PI database...\n",
      "2023-04-08 23:10:26,224 INFO:Building dataframe\n",
      "2023-04-08 23:10:26,242 INFO:Dataframe built\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:10:26,670 | INFO: Relabelling records in reference database...\n",
      "2023-04-08 23:10:26,675 | INFO: Done!\n",
      "2023-04-08 23:10:26,676 | INFO: Aligning reference database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:10:26,538 INFO:Finished building database...\n",
      "2023-04-08 23:10:26,538 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-04-08 23:10:26,538 INFO:Repset size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:10:28,842 | INFO: Inferring reference tree...\n",
      "2023-04-08 23:10:43,829 | INFO: Done!\n",
      "2023-04-08 23:10:43,831 | INFO: Relabelling tree...\n",
      "2023-04-08 23:10:44,121 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "tree_builder = ReferenceTreeBuilder(\n",
    "    input_database=Path(\"/home/robaina/Databases/OceanMicrobiome/ocean_microbiome.faa\"),\n",
    "    hmms=[\n",
    "        workdir / \"data\" / \"TIGR04244.1.HMM\",\n",
    "        workdir / \"data\" / \"TIGR04246.1.HMM\",\n",
    "    ],\n",
    "    maximum_hmm_reference_sizes=[100, 100],\n",
    "    relabel_prefixes=[\"ref44_\", \"ref46_\"],\n",
    "\n",
    "    relabel=True,\n",
    "    remove_duplicates=True,\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    output_directory=outdir,\n",
    "    msa_method=\"muscle\",\n",
    "    tree_method=\"fasttree\",\n",
    "    tree_model=\"JTT\",\n",
    ")\n",
    "tree_builder.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the generated tree, we will employ [empress](https://github.com/biocore/empress), which generates a web-based interactive tree. The following function calls empress and generates the html file. Click on the image to open the interactive tree in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robaina/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/empress/tree.py:79: TreeFormatWarning: Internal node names in the tree are not unique.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_tree_html(tree_builder.reference_tree, output_dir=outdir / \"tree_plot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"file:///home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot/empress.html\" target=\"_blank\"><img src=\"example_api/example_tree.png\" style=\"width:50%;\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess metagenomic data\n",
    "\n",
    "We need to first preprocess the metagenomic data to remove low quality reads as well as to prefilter sequences using the same profile HMM used to infer the phylogenetic tree. This will reduce the computational cost of the placement step. To this end, we can use the `QueryPreprocessor` class, which contains all necessary steps to preprocess the metagenomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:14:56,134 | INFO: Removing duplicates...\n",
      "2023-04-08 23:14:59,916 | INFO: Asserting correct sequence format...\n",
      "2023-04-08 23:15:16,493 | INFO: Done!\n",
      "2023-04-08 23:15:16,494 | INFO: Making peptide-specific reference database...\n",
      "2023-04-08 23:15:16,495 | INFO: Processing hmm TIGR04244.1 with additional arguments: --cut_ga\n",
      "2023-04-08 23:15:16,496 | INFO: Running Hmmer...\n",
      "2023-04-08 23:15:17,595 | INFO: Parsing Hmmer output file...\n",
      "2023-04-08 23:15:17,597 | INFO: Filtering Fasta...\n",
      "2023-04-08 23:15:17,801 | INFO: Filtering sequences by established length bounds...\n",
      "2023-04-08 23:15:17,811 | INFO: No reduction algorithm has been selected.\n",
      "2023-04-08 23:15:17,836 | WARNING: Could not delete temporary files: [Errno 2] No such file or directory: '/tmp/tmpo0icvlwi'\n",
      "2023-04-08 23:15:17,838 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "processor = QueryProcessor(\n",
    "    input_query=Path(\"/home/robaina/Databases/Uniprot/uniprot_sprot.fasta\"),\n",
    "    hmms=[workdir / \"data\" / \"TIGR04244.1.HMM\"],\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    minimum_sequence_length=30,\n",
    "    output_directory=outdir,\n",
    ")\n",
    "processor.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place and label sequence data\n",
    "\n",
    "In this example, we are going to use already annotated sequences from UniProt to facilitate the process. However, in a real scenario, we would typically use unannotated metagenomic data. First, download the [UniProt](https://www.uniprot.org/) database. Specifically, we will use the reviewed SwissProt database: [`uniprot_sprot.fasta`](https://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz) file, containing translated peptide sequences.\n",
    "\n",
    "We are now ready to place our query sequences onto the reference tree to infer their taxonomy and function. To this end, we will employ the `QueryLabeller` class, which will take care of all necessary steps to place  and label the metagenomic data. Namely, (i) preprocess the metagenomic data, (ii) place the sequences onto the reference tree with [papara](https://cme.h-its.org/exelixis/web/software/papara/index.html) and [epa-ng](https://github.com/pierrebarbera/epa-ng), and (iii) label placed sequences with [gappa](https://github.com/lczech/gappa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 23:16:27,592 | INFO: Removing duplicates...\n",
      "2023-04-08 23:16:27,621 | INFO: Asserting correct sequence format...\n",
      "2023-04-08 23:16:27,624 | INFO: Data already translated!\n",
      "2023-04-08 23:16:27,625 | INFO: Relabelling records...\n",
      "2023-04-08 23:16:27,628 | INFO: Done!\n",
      "2023-04-08 23:16:27,629 | INFO: Placing reads on tree...\n",
      "2023-04-08 23:16:33,313 | INFO: Writing tree with placements...\n",
      "2023-04-08 23:16:33,328 | INFO: Done!\n",
      "2023-04-08 23:16:33,330 | INFO: Filtering placements by maximum distance: \"pendant_diameter_ratio\" of 1.0\n",
      "2023-04-08 23:16:33,440 | INFO: Filtering placements for tree diameter: 3.4100473290000006\n",
      "2023-04-08 23:16:33,442 | INFO: Filtering placements by minimum LWR of: 0.8\n",
      "2023-04-08 23:16:33,896 | INFO: Done!\n",
      "2023-04-08 23:16:33,898 | INFO: Counting labelled placements...\n",
      "2023-04-08 23:16:34,801 | INFO: Done!\n",
      "2023-04-08 23:16:34,804 | INFO: Relabelling tree...\n",
      "2023-04-08 23:16:35,200 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "labeller = QueryLabeller(\n",
    "    input_query=processor.filtered_query,\n",
    "    reference_alignment=tree_builder.reference_alignment,\n",
    "    reference_tree=tree_builder.reference_tree,\n",
    "    reference_labels=[\n",
    "        tree_builder.reference_labels\n",
    "    ],\n",
    "    tree_model=\"JTT\",\n",
    "    alignment_method=\"papara\",\n",
    "    output_directory=outdir,\n",
    "    maximum_placement_distance=1.0,\n",
    "    distance_measure=\"pendant_diameter_ratio\",\n",
    "    minimum_placement_lwr=0.8,\n",
    ")\n",
    "labeller.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display placements on the reference tree\n",
    "\n",
    "We can now visualize the placements of the metagenomic data onto the reference tree. The tree was generated by the `QueryLabeller` using [gappa graft](https://github.com/lczech/gappa/wiki/Subcommand:-graft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cannot open metatag.utils.DictMerger: No such file\n"
     ]
    }
   ],
   "source": [
    "labels = DictMerger.from_pickle_paths(\n",
    "    [tree_builder.reference_labels, labeller.query_labels]\n",
    ")\n",
    "\n",
    "make_tree_html(\n",
    "    labeller.placements_tree, output_dir=outdir / \"tree_plot_placements\",\n",
    "    feature_metadata=labels\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display labelled sequences\n",
    "\n",
    "And here are the results. The following table shows the taxonomic assignments of the query sequences which has been placed onto the nosZ tree and that passed the applied distance filters (as a quality control of the placement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>LWR</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_taxopath</th>\n",
       "      <th>taxopath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query_0</td>\n",
       "      <td>sp|P94127|NOSZ_ACHCY Nitrous-oxide reductase O...</td>\n",
       "      <td>0.5441</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_1</td>\n",
       "      <td>sp|Q89XJ6|NOSZ_BRADU Nitrous-oxide reductase O...</td>\n",
       "      <td>0.5092</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query_10</td>\n",
       "      <td>sp|Q59746|NOSZ_RHIME Nitrous-oxide reductase O...</td>\n",
       "      <td>0.7280</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query_11</td>\n",
       "      <td>sp|P19573|NOSZ_STUST Nitrous-oxide reductase O...</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Gammaproteoba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_2</td>\n",
       "      <td>sp|Q8YBC6|NOSZ_BRUME Nitrous-oxide reductase O...</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>d__Bacteria;p__Proteobacteria;c__Alphaproteoba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                         query_name     LWR  \\\n",
       "0   query_0  sp|P94127|NOSZ_ACHCY Nitrous-oxide reductase O...  0.5441   \n",
       "1   query_1  sp|Q89XJ6|NOSZ_BRADU Nitrous-oxide reductase O...  0.5092   \n",
       "2  query_10  sp|Q59746|NOSZ_RHIME Nitrous-oxide reductase O...  0.7280   \n",
       "3  query_11  sp|P19573|NOSZ_STUST Nitrous-oxide reductase O...  0.5244   \n",
       "4   query_2  sp|Q8YBC6|NOSZ_BRUME Nitrous-oxide reductase O...  0.8276   \n",
       "\n",
       "  cluster_id cluster_taxopath  \\\n",
       "0         C0      Unspecified   \n",
       "1         C0      Unspecified   \n",
       "2         C0      Unspecified   \n",
       "3         C0      Unspecified   \n",
       "4         C0      Unspecified   \n",
       "\n",
       "                                            taxopath  \n",
       "0  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...  \n",
       "1  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...  \n",
       "2  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...  \n",
       "3  d__Bacteria;p__Proteobacteria;c__Gammaproteoba...  \n",
       "4  d__Bacteria;p__Proteobacteria;c__Alphaproteoba...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(labeller.taxtable, sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation\n",
    "\n",
    "We can get the citation string by calling the `cite` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this software, please cite it as below: \n",
      "Semidán Robaina Estévez (2022). MetaTag: Metagenome functional and taxonomical annotation through phylogenetic tree placement.(Version 0.1.0). Zenodo.\n"
     ]
    }
   ],
   "source": [
    "MetaTag.cite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metatag-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa7df0fb32b136e2dcfa40091bad0563b450d8cf7f0074fd349d3cdab3a7d1ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
