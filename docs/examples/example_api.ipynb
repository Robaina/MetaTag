{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/Robaina/Pynteny/blob/main/docs/examples/example_api_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/21340147/227912321-f76e622a-684d-48a9-8ead-9a2ce7caebe9.png\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "[Semidán Robaina](https://github.com/Robaina), February 2023.\n",
    "\n",
    "In this Notebook, we will use MetaTag through its Python API to reconstruct a phylogenetic tree. To this end, we will use peptide sequences from the [MARref database](https://mmp2.sfb.uit.no/marref/) and a profile HMM to identify sequences beloging to the X gene.\n",
    "\n",
    "- Note that we could have conducted the same search through Pynteny's command-line interface.\n",
    "\n",
    "- Find more info in the [documentation pages](https://robaina.github.io/MetaTag/)!\n",
    "\n",
    "Let's start by importing some required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from metatag.cli import MetaTag\n",
    "from metatag.visualization import make_tree_html\n",
    "from metatag.pipelines import ReferenceTreeBuilder, QueryLabeller, QueryProcessor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a directory to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_dir = Path(\"../../tests\")\n",
    "outdir = Path(\"example_api/results\")\n",
    "# outdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Marref database:\n",
    "\n",
    "Download the [MarRef](https://mmp2.sfb.uit.no/marref/) database and extract contents. We will use the `protein.faa` file, containing translated peptide sequences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infering a gene-specific phylogenetic tree\n",
    "\n",
    "We will infer a phylogenetic tree for the gene _nifH_. To this end, we will use the TIGRFAM profile HMM for this gene: [TIGR01287](), as well as [TIGR02016](), corresponding to gene _BCHX_ which serves as an outgroup. The class `ReferenceTreeBuilder` will take care of all necessary steps to infer the tree. Namely, (i) preprocess the input marref database, (ii) build a reference database containing a maximum of 20 nifH and 5 BCHX representative sequences, using both [CD-Hit]() and [RepSet](), (iii) align the reference sequences with [MUSCLE](), (iv) infer a phylogenetic tree from the alignment with [FastTree]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:03:29,981 | INFO: Removing duplicates...\n",
      "2023-03-30 17:03:51,653 | INFO: Asserting correct sequence format...\n",
      "2023-03-30 17:05:20,173 | INFO: Done!\n",
      "2023-03-30 17:05:20,175 | INFO: Making peptide-specific reference database...\n",
      "2023-03-30 17:05:20,176 | INFO: Processing hmm TIGR01287.1 with additional arguments: --cut_ga\n",
      "2023-03-30 17:05:20,177 | INFO: Running Hmmer...\n",
      "2023-03-30 17:05:26,143 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 17:05:26,152 | INFO: Filtering Fasta...\n",
      "2023-03-30 17:05:27,043 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 17:05:27,240 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-30 17:05:27,661 | INFO: Relabelling records in reference database...\n",
      "2023-03-30 17:05:27,663 | INFO: Processing hmm TIGR02016.1 with additional arguments: --cut_ga\n",
      "2023-03-30 17:05:27,664 | INFO: Running Hmmer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:05:27,483 INFO:Reading PI database...\n",
      "2023-03-30 17:05:27,483 INFO:Building dataframe\n",
      "2023-03-30 17:05:27,487 INFO:Dataframe built\n",
      "2023-03-30 17:05:27,571 INFO:Finished building database...\n",
      "2023-03-30 17:05:27,571 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-30 17:05:27,571 INFO:Repset size: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:05:33,583 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 17:05:33,587 | INFO: Filtering Fasta...\n",
      "2023-03-30 17:05:34,688 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 17:05:34,874 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-30 17:05:35,222 | INFO: Relabelling records in reference database...\n",
      "2023-03-30 17:05:35,226 | INFO: Done!\n",
      "2023-03-30 17:05:35,227 | INFO: Aligning reference database...\n",
      "2023-03-30 17:05:35,264 | INFO: Inferring reference tree...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:05:35,124 INFO:Reading PI database...\n",
      "2023-03-30 17:05:35,124 INFO:Building dataframe\n",
      "2023-03-30 17:05:35,126 INFO:Dataframe built\n",
      "2023-03-30 17:05:35,137 INFO:Finished building database...\n",
      "2023-03-30 17:05:35,137 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-30 17:05:35,137 INFO:Repset size: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:05:35,620 | INFO: Done!\n",
      "2023-03-30 17:05:35,622 | INFO: Relabelling tree...\n",
      "2023-03-30 17:05:35,866 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "tree_builder = ReferenceTreeBuilder(\n",
    "    input_database=Path(\"/home/robaina/Databases/MAR_database/protein.faa\"),\n",
    "    hmms=[\n",
    "        (tests_dir / \"test_data\" / \"TIGR01287.1.HMM\").as_posix(),\n",
    "        (tests_dir / \"test_data\" / \"TIGR02016.1.HMM\").as_posix(),\n",
    "    ],\n",
    "    maximum_hmm_reference_sizes=[10, 5],\n",
    "    relabel_prefixes=[\"ref_\", \"out_\"],\n",
    "    relabel=True,\n",
    "    remove_duplicates=True,\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    output_directory=outdir,\n",
    "    msa_method=\"muscle\",\n",
    "    tree_method=\"fasttree\",\n",
    "    tree_model=\"JTT\",\n",
    ")\n",
    "tree_builder.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the generated tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robaina/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/empress/tree.py:79: TreeFormatWarning: Internal node names in the tree are not unique.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_tree_html(tree_builder.reference_tree, output_dir=outdir / \"tree_plot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"file:///home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot/empress.html\" target=\"_blank\"><img src=\"example_api/example_tree.png\" style=\"width:50%;\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess metagenomic data\n",
    "\n",
    "We need to first preprocess the metagenomic data to remove low quality reads as well as to prefilter sequences using the same profile HMM used to infer the phylogenetic tree. This will reduce the computational cost of the placement step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:06:12,785 | INFO: Removing duplicates...\n",
      "2023-03-30 17:06:15,315 | INFO: Asserting correct sequence format...\n",
      "2023-03-30 17:06:30,086 | INFO: Relabelling records...\n",
      "2023-03-30 17:06:31,454 | INFO: Done!\n",
      "2023-03-30 17:06:31,456 | INFO: Making peptide-specific reference database...\n",
      "2023-03-30 17:06:31,457 | INFO: Processing hmm TIGR01287.1 with additional arguments: --cut_ga\n",
      "2023-03-30 17:06:31,458 | INFO: Running Hmmer...\n",
      "2023-03-30 17:06:32,303 | INFO: Parsing Hmmer output file...\n",
      "2023-03-30 17:06:32,347 | INFO: Filtering Fasta...\n",
      "2023-03-30 17:06:32,495 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-30 17:06:32,505 | INFO: No reduction algorithm has been selected.\n",
      "2023-03-30 17:06:32,525 | WARNING: Could not delete temporary files: [Errno 2] No such file or directory: '/tmp/tmpk53owyod'\n",
      "2023-03-30 17:06:32,526 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "processor = QueryProcessor(\n",
    "    input_query=Path(\"/home/robaina/Databases/Uniprot/uniprot_sprot.fasta\"),\n",
    "    hmm=tests_dir / \"test_data\" / \"TIGR01287.1.HMM\",\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    minimum_sequence_length=30,\n",
    "    output_directory=outdir,\n",
    "    relabel=True,\n",
    ")\n",
    "processor.run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place and label metagenomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-30 17:06:36,976 | INFO: Placing reads on tree...\n",
      "2023-03-30 17:06:37,397 | INFO: Writing tree with placements...\n",
      "2023-03-30 17:06:37,404 | INFO: Done!\n",
      "2023-03-30 17:06:37,405 | INFO: Filtering placements by maximum distance: \"pendant_diameter_ratio\" of 1.0\n",
      "2023-03-30 17:06:37,408 | INFO: Filtering placements for tree diameter: 2.5907704590000002\n",
      "2023-03-30 17:06:37,411 | INFO: Filtering placements by minimum LWR of: 0.8\n",
      "2023-03-30 17:06:37,750 | INFO: Done!\n",
      "2023-03-30 17:06:37,751 | INFO: Counting labelled placements...\n",
      "2023-03-30 17:06:38,267 | INFO: Done!\n",
      "2023-03-30 17:06:38,268 | INFO: Relabelling tree...\n",
      "2023-03-30 17:06:38,531 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "labeller = QueryLabeller(\n",
    "    input_query=processor.filtered_query,\n",
    "    skip_preprocessing=True,\n",
    "    reference_alignment=tree_builder.reference_alignment,\n",
    "    reference_tree=tree_builder.reference_tree,\n",
    "    reference_labels=[\n",
    "        tree_builder.reference_labels\n",
    "    ],\n",
    "    tree_model=\"JTT\",\n",
    "    # tree_clusters=tests_dir / \"test_data\" / \"clusters.tsv\",\n",
    "    # tree_cluster_scores=tests_dir / \"test_data\" / \"cluster_scores.tsv\",\n",
    "    # tree_cluster_score_threshold=0.6,\n",
    "    alignment_method=\"papara\",\n",
    "    output_directory=outdir,\n",
    "    maximum_placement_distance=1.0,\n",
    "    distance_measure=\"pendant_diameter_ratio\",\n",
    "    minimum_placement_lwr=0.8,\n",
    ")\n",
    "labeller.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>LWR</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_taxopath</th>\n",
       "      <th>taxopath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query_237138</td>\n",
       "      <td>query_237138</td>\n",
       "      <td>0.9468</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_237139</td>\n",
       "      <td>query_237139</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query_237140</td>\n",
       "      <td>query_237140</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query_237141</td>\n",
       "      <td>query_237141</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_237142</td>\n",
       "      <td>query_237142</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       query_id    query_name     LWR cluster_id cluster_taxopath     taxopath\n",
       "0  query_237138  query_237138  0.9468         C0      Unspecified  Unspecified\n",
       "1  query_237139  query_237139  1.0000         C0      Unspecified  Unspecified\n",
       "2  query_237140  query_237140  1.0000         C0      Unspecified  Unspecified\n",
       "3  query_237141  query_237141  1.0000         C0      Unspecified  Unspecified\n",
       "4  query_237142  query_237142  1.0000         C0      Unspecified  Unspecified"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(labeller.taxtable, sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation\n",
    "\n",
    "We can get the citation string by calling the `cite` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this software, please cite it as below: \n",
      "Semidán Robaina Estévez (2022). MetaTag: Metagenome functional and taxonomical annotation through phylogenetic tree placement.(Version 0.1.0). Zenodo.\n"
     ]
    }
   ],
   "source": [
    "MetaTag.cite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pynteny')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a61de4707cf6170489d2ddea2edd86c71e80569b354848770f4168884b6914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
