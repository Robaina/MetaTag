{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <a href=\"https://colab.research.google.com/github/Robaina/Pynteny/blob/main/docs/examples/example_api_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "<img src=\"https://user-images.githubusercontent.com/21340147/227912321-f76e622a-684d-48a9-8ead-9a2ce7caebe9.png\" style=\"width:70%;\"/>\n",
    "</div>\n",
    "<br/>\n",
    "\n",
    "[Semid√°n Robaina](https://github.com/Robaina), February 2023.\n",
    "\n",
    "In this Notebook, we will use MetaTag through its Python API to reconstruct a phylogenetic tree. To this end, we will use peptide sequences from the [MARref database](https://mmp2.sfb.uit.no/marref/) and a profile HMM to identify sequences beloging to the X gene.\n",
    "\n",
    "- Note that we could have conducted the same search through Pynteny's command-line interface.\n",
    "\n",
    "- Find more info in the [documentation pages](https://robaina.github.io/MetaTag/)!\n",
    "\n",
    "Let's start by importing some required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from metatag.cli import MetaTag\n",
    "from metatag.visualization import make_tree_html\n",
    "from metatag.pipelines import ReferenceTreeBuilder, QueryLabeller, QueryProcessor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a directory to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir = Path(\"example_api\")\n",
    "outdir = workdir / \"results\"\n",
    "# outdir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Marref database:\n",
    "\n",
    "Download the [MarRef](https://mmp2.sfb.uit.no/marref/) database and extract contents. We will use the `protein.faa` file, containing translated peptide sequences.\n",
    "\n",
    "We alo need to download two profile HMMs, click on them two download: [TIGR04244](https://ftp.ncbi.nlm.nih.gov/hmm/current/hmm_PGAP.HMM/TIGR04244.1.HMM) and [TIGR04246](https://ftp.ncbi.nlm.nih.gov/hmm/current/hmm_PGAP.HMM/TIGR04246.1.HMM)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infering a gene-specific phylogenetic tree\n",
    "\n",
    "We will infer a phylogenetic tree for the gene _nosZ_, encoding a nitrous oxide reductase that participates in the nitrogen cycle. To this end, we will use two TIGRFAM profile HMMs: [TIGR04244.1](https://www.ncbi.nlm.nih.gov/genome/annotation_prok/evidence/TIGR04244/), which encondes a TAT-dependent nitrous-oxide reductase, and [TIGR04246.1](https://www.ncbi.nlm.nih.gov/genome/annotation_prok/evidence/TIGR04246/), which encondes a SEC-dependent nitrous-oxide reductase.\n",
    "\n",
    "The class `ReferenceTreeBuilder` will take care of all necessary steps to infer the tree. Namely, (i) preprocess the input marref database, (ii) build a reference database containing a maximum of 20 nifH and 5 BCHX representative sequences, using both [CD-Hit](https://github.com/weizhongli/cdhit) and [RepSet](https://onlinelibrary.wiley.com/doi/10.1002/prot.25461), (iii) align the reference sequences with [MUSCLE](https://github.com/EddyRivasLab/hmmer), (iv) infer a phylogenetic tree from the alignment with [FastTree](https://github.com/PavelTorgashov/FastTree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:41:19,793 | INFO: Removing duplicates...\n",
      "2023-03-31 10:41:41,305 | INFO: Asserting correct sequence format...\n",
      "2023-03-31 10:43:10,256 | INFO: Done!\n",
      "2023-03-31 10:43:10,259 | INFO: Making peptide-specific reference database...\n",
      "2023-03-31 10:43:10,260 | INFO: Processing hmm TIGR04244.1 with additional arguments: --cut_ga\n",
      "2023-03-31 10:43:10,261 | INFO: Running Hmmer...\n",
      "2023-03-31 10:43:16,449 | INFO: Parsing Hmmer output file...\n",
      "2023-03-31 10:43:16,456 | INFO: Filtering Fasta...\n",
      "2023-03-31 10:43:17,364 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-31 10:43:17,605 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-31 10:43:18,038 | INFO: Relabelling records in reference database...\n",
      "2023-03-31 10:43:18,040 | INFO: Processing hmm TIGR04246.1 with additional arguments: --cut_ga\n",
      "2023-03-31 10:43:18,041 | INFO: Running Hmmer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:43:17,872 INFO:Reading PI database...\n",
      "2023-03-31 10:43:17,872 INFO:Building dataframe\n",
      "2023-03-31 10:43:17,875 INFO:Dataframe built\n",
      "2023-03-31 10:43:17,942 INFO:Finished building database...\n",
      "2023-03-31 10:43:17,942 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-31 10:43:17,942 INFO:Repset size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:43:24,249 | INFO: Parsing Hmmer output file...\n",
      "2023-03-31 10:43:24,295 | INFO: Filtering Fasta...\n",
      "2023-03-31 10:43:25,458 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-31 10:43:25,714 | INFO: Finding representative sequences for reference database...\n",
      "2023-03-31 10:43:26,130 | INFO: Relabelling records in reference database...\n",
      "2023-03-31 10:43:26,133 | INFO: Done!\n",
      "2023-03-31 10:43:26,134 | INFO: Aligning reference database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:43:25,987 INFO:Reading PI database...\n",
      "2023-03-31 10:43:25,987 INFO:Building dataframe\n",
      "2023-03-31 10:43:25,991 INFO:Dataframe built\n",
      "2023-03-31 10:43:26,037 INFO:Finished building database...\n",
      "2023-03-31 10:43:26,037 INFO:Starting mixture of summaxacross and sumsumwithin with weight 0.5...\n",
      "2023-03-31 10:43:26,037 INFO:Repset size: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 10:43:27,276 | INFO: Inferring reference tree...\n",
      "2023-03-31 10:43:34,756 | INFO: Done!\n",
      "2023-03-31 10:43:34,757 | INFO: Relabelling tree...\n",
      "2023-03-31 10:43:35,017 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "tree_builder = ReferenceTreeBuilder(\n",
    "    input_database=Path(\"/home/robaina/Databases/MAR_database/protein.faa\"),\n",
    "    hmms=[\n",
    "        workdir / \"data\" / \"TIGR04244.1.HMM\",\n",
    "        workdir / \"data\" / \"TIGR04246.1.HMM\",\n",
    "    ],\n",
    "    maximum_hmm_reference_sizes=[100, 100],\n",
    "    relabel_prefixes=[\"ref44_\", \"ref46_\"],\n",
    "    relabel=True,\n",
    "    remove_duplicates=True,\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    output_directory=outdir,\n",
    "    msa_method=\"muscle\",\n",
    "    tree_method=\"fasttree\",\n",
    "    tree_model=\"JTT\",\n",
    ")\n",
    "tree_builder.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the generated tree, we will employ [empress](https://github.com/biocore/empress), which generates a web-based interactive tree. The following function calls empress and generates the html file. Click on the image to open the interactive tree in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robaina/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/empress/tree.py:79: TreeFormatWarning: Internal node names in the tree are not unique.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_tree_html(tree_builder.reference_tree, output_dir=outdir / \"tree_plot\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"file:///home/robaina/Documents/MetaTag/docs/examples/example_api/tree_plot/empress.html\" target=\"_blank\"><img src=\"example_api/example_tree.png\" style=\"width:50%;\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess metagenomic data\n",
    "\n",
    "We need to first preprocess the metagenomic data to remove low quality reads as well as to prefilter sequences using the same profile HMM used to infer the phylogenetic tree. This will reduce the computational cost of the placement step. To this end, we can use the `QueryPreprocessor` class, which contains all necessary steps to preprocess the metagenomic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:06:54,760 | INFO: Removing duplicates...\n",
      "2023-03-31 11:06:57,267 | INFO: Asserting correct sequence format...\n",
      "2023-03-31 11:07:12,543 | INFO: Done!\n",
      "2023-03-31 11:07:12,545 | INFO: Making peptide-specific reference database...\n",
      "2023-03-31 11:07:12,546 | INFO: Processing hmm TIGR04244.1 with additional arguments: --cut_ga\n",
      "2023-03-31 11:07:12,547 | INFO: Running Hmmer...\n",
      "2023-03-31 11:07:13,616 | INFO: Parsing Hmmer output file...\n",
      "2023-03-31 11:07:13,619 | INFO: Filtering Fasta...\n",
      "2023-03-31 11:07:13,813 | INFO: Filtering sequences by established length bounds...\n",
      "2023-03-31 11:07:13,822 | INFO: No reduction algorithm has been selected.\n",
      "2023-03-31 11:07:13,845 | WARNING: Could not delete temporary files: [Errno 2] No such file or directory: '/tmp/tmpgd1o3a43'\n",
      "2023-03-31 11:07:13,846 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "processor = QueryProcessor(\n",
    "    input_query=Path(\"/home/robaina/Databases/Uniprot/uniprot_sprot.fasta\"),\n",
    "    hmms=[workdir / \"data\" / \"TIGR04244.1.HMM\"],\n",
    "    hmmsearch_args=\"--cut_ga\",\n",
    "    minimum_sequence_length=30,\n",
    "    output_directory=outdir,\n",
    ")\n",
    "processor.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place and label metagenomic data\n",
    "\n",
    "We are now ready to place our environmental sequences onto the reference tree to infer their taxonomy and function. To this end, we will employ the `QueryLabeller` class, which will take care of all necessary steps to place  and label the metagenomic data. Namely, (i) preprocess the metagenomic data, (ii) place the sequences onto the reference tree with [papara](https://cme.h-its.org/exelixis/web/software/papara/index.html) and [epa-ng](https://github.com/pierrebarbera/epa-ng), and (iii) label placed sequences with [gappa](https://github.com/lczech/gappa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-31 11:09:45,387 | INFO: Removing duplicates...\n",
      "2023-03-31 11:09:45,402 | INFO: Asserting correct sequence format...\n",
      "2023-03-31 11:09:45,403 | INFO: Data already translated!\n",
      "2023-03-31 11:09:45,404 | INFO: Relabelling records...\n",
      "2023-03-31 11:09:45,405 | INFO: Done!\n",
      "2023-03-31 11:09:45,405 | INFO: Placing reads on tree...\n",
      "2023-03-31 11:09:46,986 | INFO: Writing tree with placements...\n",
      "2023-03-31 11:09:46,996 | INFO: Done!\n",
      "2023-03-31 11:09:46,998 | INFO: Filtering placements by maximum distance: \"pendant_diameter_ratio\" of 1.0\n",
      "2023-03-31 11:09:47,016 | INFO: Filtering placements for tree diameter: 3.614263755\n",
      "2023-03-31 11:09:47,018 | INFO: Filtering placements by minimum LWR of: 0.8\n",
      "2023-03-31 11:09:47,321 | INFO: Done!\n",
      "2023-03-31 11:09:47,323 | INFO: Counting labelled placements...\n",
      "2023-03-31 11:09:47,946 | INFO: Done!\n",
      "2023-03-31 11:09:47,948 | INFO: Relabelling tree...\n",
      "2023-03-31 11:09:48,217 | INFO: Done!\n"
     ]
    }
   ],
   "source": [
    "labeller = QueryLabeller(\n",
    "    input_query=processor.filtered_query,\n",
    "    reference_alignment=tree_builder.reference_alignment,\n",
    "    reference_tree=tree_builder.reference_tree,\n",
    "    reference_labels=[\n",
    "        tree_builder.reference_labels\n",
    "    ],\n",
    "    tree_model=\"JTT\",\n",
    "    alignment_method=\"papara\",\n",
    "    output_directory=outdir,\n",
    "    maximum_placement_distance=1.0,\n",
    "    distance_measure=\"pendant_diameter_ratio\",\n",
    "    minimum_placement_lwr=0.8,\n",
    ")\n",
    "labeller.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display placements on the reference tree\n",
    "\n",
    "We can now visualize the placements of the metagenomic data onto the reference tree. The tree was generated by the `QueryLabeller` using [gappa graft](https://github.com/lczech/gappa/wiki/Subcommand:-graft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/robaina/miniconda3/envs/metatag-dev/lib/python3.10/site-packages/empress/tree.py:79: TreeFormatWarning: Internal node names in the tree are not unique.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "make_tree_html(labeller.placements_tree, output_dir=outdir / \"tree_plot_placements\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display labelled sequences\n",
    "\n",
    "And here are the results. The following table shows the taxonomic assignments of the query sequences which has been placed onto the nosZ tree and that passed the applied distance filters (as a quality control of the placement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_name</th>\n",
       "      <th>LWR</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_taxopath</th>\n",
       "      <th>taxopath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query_0</td>\n",
       "      <td>sp|P94127|NOSZ_ACHCY Nitrous-oxide reductase O...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query_1</td>\n",
       "      <td>sp|Q89XJ6|NOSZ_BRADU Nitrous-oxide reductase O...</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query_10</td>\n",
       "      <td>sp|Q59746|NOSZ_RHIME Nitrous-oxide reductase O...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query_11</td>\n",
       "      <td>sp|P19573|NOSZ_STUST Nitrous-oxide reductase O...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query_2</td>\n",
       "      <td>sp|Q8YBC6|NOSZ_BRUME Nitrous-oxide reductase O...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>C0</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query_id                                         query_name     LWR  \\\n",
       "0   query_0  sp|P94127|NOSZ_ACHCY Nitrous-oxide reductase O...  1.0000   \n",
       "1   query_1  sp|Q89XJ6|NOSZ_BRADU Nitrous-oxide reductase O...  0.9999   \n",
       "2  query_10  sp|Q59746|NOSZ_RHIME Nitrous-oxide reductase O...  1.0000   \n",
       "3  query_11  sp|P19573|NOSZ_STUST Nitrous-oxide reductase O...  1.0000   \n",
       "4   query_2  sp|Q8YBC6|NOSZ_BRUME Nitrous-oxide reductase O...  1.0000   \n",
       "\n",
       "  cluster_id cluster_taxopath     taxopath  \n",
       "0         C0      Unspecified  Unspecified  \n",
       "1         C0      Unspecified  Unspecified  \n",
       "2         C0      Unspecified  Unspecified  \n",
       "3         C0      Unspecified  Unspecified  \n",
       "4         C0      Unspecified  Unspecified  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(labeller.taxtable, sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get citation\n",
    "\n",
    "We can get the citation string by calling the `cite` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you use this software, please cite it as below: \n",
      "Semid√°n Robaina Est√©vez (2022). MetaTag: Metagenome functional and taxonomical annotation through phylogenetic tree placement.(Version 0.1.0). Zenodo.\n"
     ]
    }
   ],
   "source": [
    "MetaTag.cite()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pynteny')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72a61de4707cf6170489d2ddea2edd86c71e80569b354848770f4168884b6914"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
